{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model output: tensor([[ 1.0689,  0.2674,  0.6647,  0.5039, -0.1480]])\n",
      "Original model output: tensor([[ 1.0724,  0.2702,  0.6685,  0.5064, -0.1490]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.ao.quantization import QConfigMapping, default_dynamic_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "\n",
    "# 定义一个最简单的模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 创建模型实例\n",
    "float_model = SimpleModel()\n",
    "\n",
    "# 设置模型为评估模式\n",
    "float_model.eval()\n",
    "\n",
    "# 生成随机输入数据\n",
    "example_inputs = (torch.randn(1, 10),)\n",
    "\n",
    "# 设置量化配置\n",
    "qconfig = default_dynamic_qconfig  # 使用动态量化配置\n",
    "qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "\n",
    "# 准备模型进行量化（插入观察者）\n",
    "prepared_model = prepare_fx(float_model, qconfig_mapping, example_inputs)\n",
    "\n",
    "# 动态量化不需要校准步骤，直接转换模型\n",
    "quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "# 验证量化模型\n",
    "input_data = torch.randn(1, 10)\n",
    "output = quantized_model(input_data)\n",
    "print(\"Quantized model output:\", output)\n",
    "\n",
    "# 对比原始模型的输出\n",
    "float_output = float_model(input_data)\n",
    "print(\"Original model output:\", float_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicQuantizedLinear(in_features=10, out_features=5, dtype=torch.qint8, qscheme=torch.per_tensor_affine)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HupuKiller",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
